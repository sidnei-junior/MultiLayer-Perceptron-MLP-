{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando o MultiLayer Perceptron\n",
    "Nesse notebook vamos preparar um MLP para prever as reprovações dos alunos de Cálculo 2 na ECT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados das matriculas\n",
    "matriculas = pd.read_csv(\"data/matriculas_c2_pos_novos_indicadores.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['discente', 'faltas_unidade', 'id_turma', 'media_final', 'nota',\n",
       "       'numero_total_faltas', 'reposicao', 'unidade', 'reprovou',\n",
       "       'desempenho_exatas', 'historico_reprovacao', 'primeira_vez_pagando',\n",
       "       'n1_std_turma', 'prof_c1_tx_reprovacao', 'professor_tx_reprovao'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriculas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alunos = matriculas[['nota', 'n1_std_turma', 'desempenho_exatas', 'primeira_vez_pagando',\n",
    "       'historico_reprovacao', 'prof_c1_tx_reprovacao', 'reprovou']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo\n",
    "Vamos preparar o MLP para rodar com nossos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2404,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = alunos.drop(\"reprovou\", axis=1)\n",
    "y = alunos.reprovou.values\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.astype('int32')\n",
    "X_test = X_test.values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense( activation = 'relu', input_dim = 6, units = 16, kernel_initializer = 'uniform'))\n",
    "\n",
    "classifier.add(keras.layers.core.Dropout(rate=0.5))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "# classifier.add(Dense( activation = 'relu', units = 12, kernel_initializer = 'uniform' ))\n",
    "\n",
    "# classifier.add(keras.layers.core.Dropout(rate=0.4))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "# classifier.add(Dense( activation = 'relu', units = 6, kernel_initializer = 'uniform' ))\n",
    "\n",
    "# classifier.add(keras.layers.core.Dropout(rate=0.5))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense( activation = 'si'gmoid', units = 2, kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                112       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1923 samples, validate on 481 samples\n",
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 0s 158us/step - loss: 0.6875 - acc: 0.6505 - val_loss: 0.6788 - val_acc: 0.7131\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 0s 17us/step - loss: 0.6745 - acc: 0.7083 - val_loss: 0.6660 - val_acc: 0.7568\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 0s 19us/step - loss: 0.6599 - acc: 0.7421 - val_loss: 0.6474 - val_acc: 0.7568\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.6445 - acc: 0.7332 - val_loss: 0.6309 - val_acc: 0.7568\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.6287 - acc: 0.7410 - val_loss: 0.6146 - val_acc: 0.7692\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.6130 - acc: 0.7634 - val_loss: 0.5968 - val_acc: 0.7651\n",
      "Epoch 7/20\n",
      "1923/1923 [==============================] - 0s 22us/step - loss: 0.5934 - acc: 0.7764 - val_loss: 0.5763 - val_acc: 0.7692\n",
      "Epoch 8/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.5791 - acc: 0.7707 - val_loss: 0.5617 - val_acc: 0.8025\n",
      "Epoch 9/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.5659 - acc: 0.7754 - val_loss: 0.5467 - val_acc: 0.8108\n",
      "Epoch 10/20\n",
      "1923/1923 [==============================] - 0s 17us/step - loss: 0.5605 - acc: 0.7702 - val_loss: 0.5323 - val_acc: 0.8150\n",
      "Epoch 11/20\n",
      "1923/1923 [==============================] - 0s 16us/step - loss: 0.5413 - acc: 0.7826 - val_loss: 0.5169 - val_acc: 0.8087\n",
      "Epoch 12/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.5368 - acc: 0.7754 - val_loss: 0.5053 - val_acc: 0.8170\n",
      "Epoch 13/20\n",
      "1923/1923 [==============================] - 0s 19us/step - loss: 0.5276 - acc: 0.7858 - val_loss: 0.4941 - val_acc: 0.8150\n",
      "Epoch 14/20\n",
      "1923/1923 [==============================] - 0s 24us/step - loss: 0.5124 - acc: 0.7884 - val_loss: 0.4831 - val_acc: 0.8129\n",
      "Epoch 15/20\n",
      "1923/1923 [==============================] - 0s 22us/step - loss: 0.5086 - acc: 0.7936 - val_loss: 0.4728 - val_acc: 0.8129\n",
      "Epoch 16/20\n",
      "1923/1923 [==============================] - 0s 22us/step - loss: 0.4985 - acc: 0.7915 - val_loss: 0.4659 - val_acc: 0.8108\n",
      "Epoch 17/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.4923 - acc: 0.7910 - val_loss: 0.4585 - val_acc: 0.8108\n",
      "Epoch 18/20\n",
      "1923/1923 [==============================] - 0s 18us/step - loss: 0.4912 - acc: 0.7759 - val_loss: 0.4517 - val_acc: 0.8108\n",
      "Epoch 19/20\n",
      "1923/1923 [==============================] - 0s 21us/step - loss: 0.4840 - acc: 0.7904 - val_loss: 0.4482 - val_acc: 0.8108\n",
      "Epoch 20/20\n",
      "1923/1923 [==============================] - 0s 20us/step - loss: 0.4866 - acc: 0.7920 - val_loss: 0.4439 - val_acc: 0.8108\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
